{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c56b3c",
   "metadata": {},
   "source": [
    "# Testing all models with balanced (at 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a82689d",
   "metadata": {},
   "source": [
    "## Imports required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf3cbe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error,r2_score,accuracy_score, confusion_matrix,f1_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier ,KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor, StackingClassifier\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d89fab",
   "metadata": {},
   "source": [
    "## Regression models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b452f5c0",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae45a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"balanced60.csv\")\n",
    "\n",
    "X = df.drop(columns=['popularity'])  # Replace 'target_column' with your actual target variable\n",
    "y = df['popularity']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train = y_train.squeeze()\n",
    "y_test = y_test.squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3964fc5",
   "metadata": {},
   "source": [
    "### Linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4b9620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 416.5355\n",
      "R-squared Score: 0.0259\n",
      "Model Accuracy (with ±10% tolerance): 35.46%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation\n",
    "tolerance = 10  # Absolute error margin\n",
    "\n",
    "# Count correct predictions within tolerance\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "\n",
    "print(f\"Model Accuracy (with ±{tolerance}% tolerance): {accuracy_with_tolerance:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1aa9f2",
   "metadata": {},
   "source": [
    "### Polynomial Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817ce53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 409.7253\n",
      "R-squared Score: 0.0419\n",
      "Model Accuracy (with ±10% tolerance): 36.54%\n"
     ]
    }
   ],
   "source": [
    "# Set polynomial degree\n",
    "degree = 3  # You can experiment with higher degrees\n",
    "\n",
    "# Transform features into polynomial features\n",
    "poly = PolynomialFeatures(degree=degree)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test_poly, y_test)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation\n",
    "tolerance = 10  # Absolute error margin\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "\n",
    "print(f\"Model Accuracy (with ±{tolerance}% tolerance): {accuracy_with_tolerance:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7b7668",
   "metadata": {},
   "source": [
    "### KNN Regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e2ffed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 494.6176\n",
      "R-squared Score: -0.1567\n",
      "Model Accuracy (with ±10 margin): 37.00%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model (choose k=5 as a starting point)\n",
    "model = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation (±10 margin)\n",
    "tolerance = 10  # Absolute error margin\n",
    "\n",
    "# Count correct predictions within tolerance\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "\n",
    "# Calculate tolerance-based accuracy\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "print(f\"Model Accuracy (with ±{tolerance} margin): {accuracy_with_tolerance:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5057f5ad",
   "metadata": {},
   "source": [
    "### Random Forest Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b3c6199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 424.3915\n",
      "R-squared Score: 0.0076\n",
      "Model Accuracy (with ±10 margin): 36.79%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation (±10 margin)\n",
    "tolerance = 10  # Absolute error margin\n",
    "\n",
    "# Count correct predictions within tolerance\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "\n",
    "# Calculate tolerance-based accuracy\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "print(f\"Model Accuracy (with ±{tolerance} margin): {accuracy_with_tolerance:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f0665",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9af503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 426.9038\n",
      "R-squared Score: 0.0017\n",
      "Model Accuracy (with ±10 margin): 42.82%\n"
     ]
    }
   ],
   "source": [
    "# Standardize features and target\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# Reshape y to 2D before scaling, then back to 1D\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Initialize the model with RBF kernel (default)\n",
    "model = SVR(kernel='rbf')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation (±10 margin)\n",
    "tolerance = 10  # Absolute error margin\n",
    "\n",
    "# Count correct predictions within tolerance\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "\n",
    "# Calculate tolerance-based accuracy\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "print(f\"Model Accuracy (with ±{tolerance} margin): {accuracy_with_tolerance:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2619366",
   "metadata": {},
   "source": [
    "## Classification models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515407ae",
   "metadata": {},
   "source": [
    "### Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c30121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 60\n",
      "Model Accuracy: 56.82%\n",
      "F1 Score: 0.5276690888764674\n",
      "Confusion Matrix:\n",
      "[[640 389]\n",
      " [456 472]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced60.csv\")\n",
    "\n",
    "threshold = 60  # Set threshold to 70\n",
    "\n",
    "# Create a fresh copy of the data\n",
    "data = df.copy()\n",
    "\n",
    "# Convert popularity to binary based on the threshold\n",
    "data['popularity'] = (data['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(columns=['popularity'])\n",
    "y = data['popularity']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Threshold: {threshold}\")\n",
    "print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec778a64",
   "metadata": {},
   "source": [
    "### KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "042241f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 60\n",
      "KNN Model with k=25\n",
      "Model Accuracy: 58.87%\n",
      "F1 Score: 0.5783132530120482\n",
      "Confusion Matrix:\n",
      "[[600 429]\n",
      " [376 552]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced60.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 60\n",
    "print(\"=\" * 50)\n",
    "print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "# Binarize target based on threshold\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# KNN model\n",
    "k = 25\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"KNN Model with k={k}\")\n",
    "print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc8677",
   "metadata": {},
   "source": [
    "### RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03f1a882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 60\n",
      "Model Accuracy: 59.27%\n",
      "F1 Score: 0.5721953837895867\n",
      "Confusion Matrix:\n",
      " [[627 402]\n",
      " [395 533]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced60.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 60\n",
    "print(\"=\" * 50)\n",
    "print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "# Convert target variable: Popularity > threshold → 1, else 0\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Split data (80% train, 20% test) with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Feature scaling (optional for Random Forest, but kept for consistency)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train Random Forest model\n",
    "rfc = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    max_depth=20,\n",
    "    min_samples_split=5\n",
    ")\n",
    "rfc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rfc.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08d0e2",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59f35634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 60\n",
      "SVM Model Accuracy: 58.97%\n",
      "F1 Score: 0.5930055752660922\n",
      "Confusion Matrix:\n",
      " [[569 460]\n",
      " [343 585]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced60.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 60\n",
    "print(\"=\" * 50)\n",
    "print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "# Convert popularity to binary target\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train SVM\n",
    "svm = SVC(kernel='rbf', C=1, probability=True, random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"SVM Model Accuracy: {accuracy:.2f}%\")\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5597c4",
   "metadata": {},
   "source": [
    "### XGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c789f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 60\n",
      "XGBoost Model Accuracy: 56.00%\n",
      "F1 Score: 0.6664083688492832\n",
      "Confusion Matrix:\n",
      "\n",
      "[[236 793]\n",
      " [ 68 860]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced60.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 60\n",
    "print(\"=\" * 50)\n",
    "print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "# Convert popularity to binary based on threshold\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=5\n",
    ")\n",
    "\n",
    "# Train model\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = xgb.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"XGBoost Model Accuracy: {accuracy:.2f}%\")\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d7f3ee",
   "metadata": {},
   "source": [
    "### stacking models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "307e02bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Accuracy: 59.53%\n",
      "F1 Score: 0.5540540540540541\n",
      "Confusion Matrix:\n",
      "[[673 356]\n",
      " [436 492]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced60.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 60\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('svm', SVC(kernel='rbf', C=1, probability=True, random_state=42)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# Define meta-model (stacker)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create StackingClassifier\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Train stacked model\n",
    "stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = stacked_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Stacked Model Accuracy: {accuracy:.2f}%\")\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e5e4ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Accuracy: 80.58%\n",
      "F1 Score: 0.010416666666666666\n",
      "Confusion Matrix:\n",
      "[[1575    1]\n",
      " [ 379    2]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced60.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 70\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('svm', SVC(kernel='rbf', C=1, probability=True, random_state=42)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "\n",
    "]\n",
    "\n",
    "# Define meta-model (stacker)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create StackingClassifier\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Train stacked model\n",
    "stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = stacked_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Stacked Model Accuracy: {accuracy:.2f}%\")\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb8099d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Accuracy: 80.48%\n",
      "F1 Score: 0.030456852791878174\n",
      "Confusion Matrix:\n",
      "[[1569    7]\n",
      " [ 375    6]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced60.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 70\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# Define meta-model (stacker)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create StackingClassifier\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Train stacked model\n",
    "stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = stacked_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Stacked Model Accuracy: {accuracy:.2f}%\")\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3f8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
