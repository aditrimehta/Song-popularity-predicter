{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c56b3c",
   "metadata": {},
   "source": [
    "# Testing all models with cleaned data (imbalanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a82689d",
   "metadata": {},
   "source": [
    "## Imports required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf3cbe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error,r2_score,accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.svm import SVR,SVC\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.neighbors import KNeighborsClassifier ,KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor, StackingClassifier\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d89fab",
   "metadata": {},
   "source": [
    "## Regression models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b452f5c0",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae45a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "X = df.drop(columns=['popularity'])  # Replace 'target_column' with your actual target variable\n",
    "y = df['popularity']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train = y_train.squeeze()\n",
    "y_test = y_test.squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3964fc5",
   "metadata": {},
   "source": [
    "### Linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c4b9620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 401.3028\n",
      "R-squared Score: 0.0179\n",
      "Model Accuracy (with ±10% tolerance): 38.83%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation\n",
    "tolerance = 10  # Absolute error margin\n",
    "\n",
    "# Count correct predictions within tolerance\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "\n",
    "print(f\"Model Accuracy (with ±{tolerance}% tolerance): {accuracy_with_tolerance:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1aa9f2",
   "metadata": {},
   "source": [
    "### Polynomial Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "817ce53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 393.4078\n",
      "R-squared Score: 0.0372\n",
      "Model Accuracy (with ±10% tolerance): 39.66%\n"
     ]
    }
   ],
   "source": [
    "# Set polynomial degree\n",
    "degree = 3  # You can experiment with higher degrees\n",
    "\n",
    "# Transform features into polynomial features\n",
    "poly = PolynomialFeatures(degree=degree)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test_poly, y_test)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation\n",
    "tolerance = 10  # Absolute error margin\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "\n",
    "print(f\"Model Accuracy (with ±{tolerance}% tolerance): {accuracy_with_tolerance:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7b7668",
   "metadata": {},
   "source": [
    "### KNN Regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91e2ffed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 466.0415\n",
      "R-squared Score: -0.1406\n",
      "Model Accuracy (with ±10 margin): 36.85%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model (choose k=5 as a starting point)\n",
    "model = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation (±10 margin)\n",
    "tolerance = 10  # Absolute error margin\n",
    "\n",
    "# Count correct predictions within tolerance\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "\n",
    "# Calculate tolerance-based accuracy\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "print(f\"Model Accuracy (with ±{tolerance} margin): {accuracy_with_tolerance:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5057f5ad",
   "metadata": {},
   "source": [
    "### Random Forest Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b3c6199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 410.3948\n",
      "R-squared Score: -0.0044\n",
      "Model Accuracy (with ±10 margin): 38.56%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation (±10 margin)\n",
    "tolerance = 10  # Absolute error margin\n",
    "\n",
    "# Count correct predictions within tolerance\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "\n",
    "# Calculate tolerance-based accuracy\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "print(f\"Model Accuracy (with ±{tolerance} margin): {accuracy_with_tolerance:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f0665",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9af503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 405.9112\n",
      "R-squared Score: 0.0066\n",
      "Model Accuracy (with ±10 margin): 43.08%\n"
     ]
    }
   ],
   "source": [
    "# Standardize features and target\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# Reshape y to 2D before scaling, then back to 1D\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Initialize the model with RBF kernel (default)\n",
    "model = SVR(kernel='rbf')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation (±10 margin)\n",
    "tolerance = 10  # Absolute error margin\n",
    "\n",
    "# Count correct predictions within tolerance\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "\n",
    "# Calculate tolerance-based accuracy\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "print(f\"Model Accuracy (with ±{tolerance} margin): {accuracy_with_tolerance:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2619366",
   "metadata": {},
   "source": [
    "## Classification models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515407ae",
   "metadata": {},
   "source": [
    "### Logistical Regression (without SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c30121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Testing Threshold: 50\n",
      "Model Accuracy: 57.65%\n",
      "Confusion Matrix:\n",
      "[[ 497  916]\n",
      " [ 348 1224]]\n",
      "========================================\n",
      "Testing Threshold: 60\n",
      "Model Accuracy: 68.91%\n",
      "Confusion Matrix:\n",
      "[[2057    0]\n",
      " [ 928    0]]\n",
      "========================================\n",
      "Testing Threshold: 70\n",
      "Model Accuracy: 87.24%\n",
      "Confusion Matrix:\n",
      "[[2604    0]\n",
      " [ 381    0]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "# Loop over each threshold\n",
    "# Define thresholds to test\n",
    "thresholds = [50, 60, 70]\n",
    "for threshold in thresholds:\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Testing Threshold: {threshold}\")\n",
    "    \n",
    "    # Create a fresh copy of the data each time\n",
    "    data = df.copy()\n",
    "\n",
    "    # Convert popularity to binary based on current threshold\n",
    "    data['popularity'] = (data['popularity'] > threshold).astype(int)\n",
    "\n",
    "    # Define features and target\n",
    "    X = data.drop(columns=['popularity'])\n",
    "    y = data['popularity']\n",
    "\n",
    "    # Train-test split with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train Logistic Regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "    print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3634c9c4",
   "metadata": {},
   "source": [
    "### Logistical regression with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfa2369c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 70\n",
      "Model Accuracy: 84.99%\n",
      "Confusion Matrix:\n",
      "[[2502  102]\n",
      " [ 346   35]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "threshold = 70\n",
    "print(\"=\" * 50)\n",
    "print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "# Convert popularity to binary\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Apply SMOTE to training data\n",
    "smote = SMOTE(random_state=42, sampling_strategy=0.5)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec778a64",
   "metadata": {},
   "source": [
    "### KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "042241f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 50\n",
      "KNN Model with k=5\n",
      "Model Accuracy: 55.34%\n",
      "Confusion Matrix:\n",
      "[[691 722]\n",
      " [611 961]]\n",
      "==================================================\n",
      "Testing Threshold: 60\n",
      "KNN Model with k=5\n",
      "Model Accuracy: 63.12%\n",
      "Confusion Matrix:\n",
      "[[1637  420]\n",
      " [ 681  247]]\n",
      "==================================================\n",
      "Testing Threshold: 70\n",
      "KNN Model with k=5\n",
      "Model Accuracy: 84.96%\n",
      "Confusion Matrix:\n",
      "[[2512   92]\n",
      " [ 357   24]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "thresholds = [50, 60, 70]\n",
    "\n",
    "# Number of neighbors for KNN\n",
    "k = 5\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "    # Copy the original data\n",
    "    data = df.copy()\n",
    "\n",
    "    # Binarize target based on threshold\n",
    "    data['popularity'] = (data['popularity'] > threshold).astype(int)\n",
    "\n",
    "    # Define features and target\n",
    "    X = data.drop(columns=['popularity'])\n",
    "    y = data['popularity']\n",
    "\n",
    "    # Train-test split with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "    print(f\"KNN Model with k={k}\")\n",
    "    print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc8677",
   "metadata": {},
   "source": [
    "### RFC without smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03f1a882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 50\n",
      "Model Accuracy: 58.22%\n",
      "Confusion Matrix:\n",
      " [[ 686  727]\n",
      " [ 520 1052]]\n",
      "==================================================\n",
      "Testing Threshold: 60\n",
      "Model Accuracy: 67.40%\n",
      "Confusion Matrix:\n",
      " [[1760  297]\n",
      " [ 676  252]]\n",
      "==================================================\n",
      "Testing Threshold: 70\n",
      "Model Accuracy: 83.99%\n",
      "Confusion Matrix:\n",
      " [[2461  143]\n",
      " [ 335   46]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Thresholds to test\n",
    "thresholds = [50,60, 70]\n",
    "\n",
    "# Loop over thresholds\n",
    "for threshold in thresholds:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "    # Convert target variable: Popularity > threshold → 1, else 0\n",
    "    data = df.copy()\n",
    "    data['popularity'] = (data['popularity'] > threshold).astype(int)\n",
    "\n",
    "    # Define features and target\n",
    "    X = data.drop(columns=['popularity'])\n",
    "    y = data['popularity']\n",
    "\n",
    "    # Split data (80% train, 20% test) with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Feature scaling (optional for Random Forest, but kept for consistency)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize and train Random Forest model\n",
    "    rfc = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        max_depth=20,\n",
    "        min_samples_split=5\n",
    "    )\n",
    "    rfc.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rfc.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "    print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c57dec",
   "metadata": {},
   "source": [
    "### RFC with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f1354d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 60\n",
      "Model Accuracy: 66.40%\n",
      "Confusion Matrix:\n",
      " [[1697  360]\n",
      " [ 643  285]]\n",
      "==================================================\n",
      "Testing Threshold: 70\n",
      "Model Accuracy: 74.30%\n",
      "Confusion Matrix:\n",
      " [[2088  516]\n",
      " [ 251  130]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Thresholds to test\n",
    "thresholds = [60, 70]\n",
    "\n",
    "# Loop over each threshold\n",
    "for threshold in thresholds:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "    # Convert target variable: Popularity > threshold → 1, else 0\n",
    "    data = df.copy()\n",
    "    data['popularity'] = (data['popularity'] > threshold).astype(int)\n",
    "\n",
    "    # Define features and target\n",
    "    X = data.drop(columns=['popularity'])\n",
    "    y = data['popularity']\n",
    "\n",
    "    # Split data (80% train, 20% test) with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Apply SMOTE to training data\n",
    "    smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize and train Random Forest model\n",
    "    rfc = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        max_depth=20,\n",
    "        min_samples_split=5\n",
    "    )\n",
    "    rfc.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rfc.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "    print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08d0e2",
   "metadata": {},
   "source": [
    "### SVM without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59f35634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 50\n",
      "SVM Model Accuracy: 59.73%\n",
      "Confusion Matrix:\n",
      " [[ 489  924]\n",
      " [ 278 1294]]\n",
      "==================================================\n",
      "Testing Threshold: 60\n",
      "SVM Model Accuracy: 68.84%\n",
      "Confusion Matrix:\n",
      " [[2055    2]\n",
      " [ 928    0]]\n",
      "==================================================\n",
      "Testing Threshold: 70\n",
      "SVM Model Accuracy: 87.24%\n",
      "Confusion Matrix:\n",
      " [[2604    0]\n",
      " [ 381    0]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Define thresholds to loop over\n",
    "thresholds = [50, 60, 70]\n",
    "\n",
    "# Loop over thresholds\n",
    "for threshold in thresholds:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "    # Convert popularity to binary target\n",
    "    data = df.copy()\n",
    "    data['popularity'] = (data['popularity'] > threshold).astype(int)\n",
    "\n",
    "    # Define features and target\n",
    "    X = data.drop(columns=['popularity'])\n",
    "    y = data['popularity']\n",
    "\n",
    "    # Train-test split with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize and train SVM\n",
    "    svm = SVC(kernel='rbf', C=1, probability=True, random_state=42)\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "    print(f\"SVM Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d618a5cd",
   "metadata": {},
   "source": [
    "### SVM with smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0cc9928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 60\n",
      "SVM Model Accuracy: 68.81%\n",
      "Confusion Matrix:\n",
      " [[2054    3]\n",
      " [ 928    0]]\n",
      "==================================================\n",
      "Testing Threshold: 70\n",
      "SVM Model Accuracy: 81.64%\n",
      "Confusion Matrix:\n",
      " [[2367  237]\n",
      " [ 311   70]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Thresholds to evaluate\n",
    "thresholds = [60, 70]\n",
    "\n",
    "# Loop over each threshold\n",
    "for threshold in thresholds:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "    # Convert target to binary\n",
    "    data = df.copy()\n",
    "    data['popularity'] = (data['popularity'] > threshold).astype(int)\n",
    "\n",
    "    # Define features and target\n",
    "    X = data.drop(columns=['popularity'])\n",
    "    y = data['popularity']\n",
    "\n",
    "    # Train-test split with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Apply SMOTE to training data\n",
    "    smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize and train SVM model\n",
    "    svm = SVC(kernel='rbf', C=1, probability=True, random_state=42)\n",
    "    svm.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate model\n",
    "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "    print(f\"SVM Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5597c4",
   "metadata": {},
   "source": [
    "### XGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c789f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 50\n",
      "XGBoost Model Accuracy: 55.88%\n",
      "Confusion Matrix:\n",
      " [[ 181 1232]\n",
      " [  85 1487]]\n",
      "==================================================\n",
      "Testing Threshold: 60\n",
      "XGBoost Model Accuracy: 50.35%\n",
      "Confusion Matrix:\n",
      " [[ 794 1263]\n",
      " [ 219  709]]\n",
      "==================================================\n",
      "Testing Threshold: 70\n",
      "XGBoost Model Accuracy: 77.72%\n",
      "Confusion Matrix:\n",
      " [[2205  399]\n",
      " [ 266  115]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Thresholds to test\n",
    "thresholds = [50, 60, 70]\n",
    "\n",
    "# Loop through thresholds\n",
    "for threshold in thresholds:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "    # Convert popularity to binary based on threshold\n",
    "    data = df.copy()\n",
    "    data['popularity'] = (data['popularity'] > threshold).astype(int)\n",
    "\n",
    "    # Define features and target\n",
    "    X = data.drop(columns=['popularity'])\n",
    "    y = data['popularity']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # XGBoost Classifier\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        random_state=42,\n",
    "        scale_pos_weight=5  # You can also set this dynamically if needed\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = xgb.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "    print(f\"XGBoost Model Accuracy: {accuracy:.2f}%\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d8fdc",
   "metadata": {},
   "source": [
    "### Stacking models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "307e02bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 50\n",
      "Stacked Model Accuracy: 59.06%\n",
      "Confusion Matrix:\n",
      "[[ 600  813]\n",
      " [ 409 1163]]\n",
      "==================================================\n",
      "Testing Threshold: 60\n",
      "Stacked Model Accuracy: 68.51%\n",
      "Confusion Matrix:\n",
      "[[2007   50]\n",
      " [ 890   38]]\n",
      "==================================================\n",
      "Testing Threshold: 70\n",
      "Stacked Model Accuracy: 87.17%\n",
      "Confusion Matrix:\n",
      "[[2595    9]\n",
      " [ 374    7]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Thresholds to evaluate\n",
    "thresholds = [50, 60, 70]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "    # Prepare data\n",
    "    data = df.copy()\n",
    "    data['popularity'] = (data['popularity'] > threshold).astype(int)\n",
    "\n",
    "    X = data.drop(columns=['popularity'])\n",
    "    y = data['popularity']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Define base models\n",
    "    base_models = [\n",
    "        ('svm', SVC(kernel='rbf', C=1, probability=True, random_state=42)),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "        ('rfc', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ]\n",
    "\n",
    "    # Define meta-model\n",
    "    meta_model = LogisticRegression()\n",
    "\n",
    "    # Stacking classifier\n",
    "    stacked_model = StackingClassifier(\n",
    "        estimators=base_models,\n",
    "        final_estimator=meta_model,\n",
    "        cv=5\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = stacked_model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "    print(f\"Stacked Model Accuracy: {accuracy:.2f}%\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "841b4a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 50\n",
      "Stacked Model Accuracy: 59.33%\n",
      "Confusion Matrix:\n",
      "[[ 568  845]\n",
      " [ 369 1203]]\n",
      "==================================================\n",
      "Testing Threshold: 60\n",
      "Stacked Model Accuracy: 68.84%\n",
      "Confusion Matrix:\n",
      "[[2053    4]\n",
      " [ 926    2]]\n",
      "==================================================\n",
      "Testing Threshold: 70\n",
      "Stacked Model Accuracy: 87.24%\n",
      "Confusion Matrix:\n",
      "[[2604    0]\n",
      " [ 381    0]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Thresholds to evaluate\n",
    "thresholds = [50, 60, 70]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "    # Prepare data\n",
    "    data = df.copy()\n",
    "    data['popularity'] = (data['popularity'] > threshold).astype(int)\n",
    "\n",
    "    X = data.drop(columns=['popularity'])\n",
    "    y = data['popularity']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Define base models\n",
    "    base_models = [\n",
    "        ('svm', SVC(kernel='rbf', C=1, probability=True, random_state=42)),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ]\n",
    "\n",
    "    # Define meta-model\n",
    "    meta_model = LogisticRegression()\n",
    "\n",
    "    # Stacking classifier\n",
    "    stacked_model = StackingClassifier(\n",
    "        estimators=base_models,\n",
    "        final_estimator=meta_model,\n",
    "        cv=5\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = stacked_model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "    print(f\"Stacked Model Accuracy: {accuracy:.2f}%\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f67ea6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 50\n",
      "Stacked Model Accuracy: 57.99%\n",
      "Confusion Matrix:\n",
      "[[ 605  808]\n",
      " [ 446 1126]]\n",
      "==================================================\n",
      "Testing Threshold: 60\n",
      "Stacked Model Accuracy: 68.54%\n",
      "Confusion Matrix:\n",
      "[[2006   51]\n",
      " [ 888   40]]\n",
      "==================================================\n",
      "Testing Threshold: 70\n",
      "Stacked Model Accuracy: 87.17%\n",
      "Confusion Matrix:\n",
      "[[2595    9]\n",
      " [ 374    7]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Thresholds to evaluate\n",
    "thresholds = [50, 60, 70]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "    # Prepare data\n",
    "    data = df.copy()\n",
    "    data['popularity'] = (data['popularity'] > threshold).astype(int)\n",
    "\n",
    "    X = data.drop(columns=['popularity'])\n",
    "    y = data['popularity']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Define base models\n",
    "    base_models = [\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "        ('rfc', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ]\n",
    "\n",
    "    # Define meta-model\n",
    "    meta_model = LogisticRegression()\n",
    "\n",
    "    # Stacking classifier\n",
    "    stacked_model = StackingClassifier(\n",
    "        estimators=base_models,\n",
    "        final_estimator=meta_model,\n",
    "        cv=5\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = stacked_model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "    print(f\"Stacked Model Accuracy: {accuracy:.2f}%\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fcc927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
