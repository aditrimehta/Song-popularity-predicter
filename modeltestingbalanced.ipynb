{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c56b3c",
   "metadata": {},
   "source": [
    "# Testing all models with balanced (at 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a82689d",
   "metadata": {},
   "source": [
    "## Imports required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf3cbe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error,r2_score,accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.svm import SVR,SVC\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.neighbors import KNeighborsClassifier ,KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor, StackingClassifier\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d89fab",
   "metadata": {},
   "source": [
    "## Regression models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b452f5c0",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae45a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"balanced.csv\")\n",
    "\n",
    "X = df.drop(columns=['popularity'])  # Replace 'target_column' with your actual target variable\n",
    "y = df['popularity']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train = y_train.squeeze()\n",
    "y_test = y_test.squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3964fc5",
   "metadata": {},
   "source": [
    "### Linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c4b9620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 424.5210\n",
      "R-squared Score: 0.0795\n",
      "Model Accuracy (with ±10% tolerance): 29.27%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation\n",
    "tolerance = 10  # Absolute error margin\n",
    "\n",
    "# Count correct predictions within tolerance\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "\n",
    "print(f\"Model Accuracy (with ±{tolerance}% tolerance): {accuracy_with_tolerance:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1aa9f2",
   "metadata": {},
   "source": [
    "### Polynomial Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "817ce53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 408.0189\n",
      "R-squared Score: 0.1153\n",
      "Model Accuracy (with ±10% tolerance): 33.42%\n"
     ]
    }
   ],
   "source": [
    "# Set polynomial degree\n",
    "degree = 3  # You can experiment with higher degrees\n",
    "\n",
    "# Transform features into polynomial features\n",
    "poly = PolynomialFeatures(degree=degree)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test_poly, y_test)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation\n",
    "tolerance = 10  # Absolute error margin\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "\n",
    "print(f\"Model Accuracy (with ±{tolerance}% tolerance): {accuracy_with_tolerance:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7b7668",
   "metadata": {},
   "source": [
    "### KNN Regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91e2ffed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 513.2436\n",
      "R-squared Score: -0.1128\n",
      "Model Accuracy (with ±10 margin): 37.05%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model (choose k=5 as a starting point)\n",
    "model = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation (±10 margin)\n",
    "tolerance = 10  # Absolute error margin\n",
    "\n",
    "# Count correct predictions within tolerance\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "\n",
    "# Calculate tolerance-based accuracy\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "print(f\"Model Accuracy (with ±{tolerance} margin): {accuracy_with_tolerance:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5057f5ad",
   "metadata": {},
   "source": [
    "### Random Forest Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b3c6199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 431.5407\n",
      "R-squared Score: 0.0643\n",
      "Model Accuracy (with ±10 margin): 35.36%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation (±10 margin)\n",
    "tolerance = 10  # Absolute error margin\n",
    "\n",
    "# Count correct predictions within tolerance\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "\n",
    "# Calculate tolerance-based accuracy\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "print(f\"Model Accuracy (with ±{tolerance} margin): {accuracy_with_tolerance:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f0665",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9af503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 430.1851\n",
      "R-squared Score: 0.0673\n",
      "Model Accuracy (with ±10 margin): 48.32%\n"
     ]
    }
   ],
   "source": [
    "# Standardize features and target\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# Reshape y to 2D before scaling, then back to 1D\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Initialize the model with RBF kernel (default)\n",
    "model = SVR(kernel='rbf')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Calculate Mean Squared Error & R-squared Score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# Tolerance-Based Accuracy Calculation (±10 margin)\n",
    "tolerance = 10  # Absolute error margin\n",
    "\n",
    "# Count correct predictions within tolerance\n",
    "correct_predictions = np.sum(np.abs(y_test - y_pred) <= tolerance)\n",
    "\n",
    "# Calculate tolerance-based accuracy\n",
    "accuracy_with_tolerance = (correct_predictions / len(y_test)) * 100\n",
    "print(f\"Model Accuracy (with ±{tolerance} margin): {accuracy_with_tolerance:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2619366",
   "metadata": {},
   "source": [
    "## Classification models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515407ae",
   "metadata": {},
   "source": [
    "### Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c30121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 70\n",
      "Model Accuracy: 61.27%\n",
      "Confusion Matrix:\n",
      "[[211 180]\n",
      " [119 262]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced.csv\")\n",
    "\n",
    "threshold = 70  # Set threshold to 70\n",
    "\n",
    "# Create a fresh copy of the data\n",
    "data = df.copy()\n",
    "\n",
    "# Convert popularity to binary based on the threshold\n",
    "data['popularity'] = (data['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(columns=['popularity'])\n",
    "y = data['popularity']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Threshold: {threshold}\")\n",
    "print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec778a64",
   "metadata": {},
   "source": [
    "### KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "042241f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 70\n",
      "KNN Model with k=5\n",
      "Model Accuracy: 58.16%\n",
      "Confusion Matrix:\n",
      "[[207 184]\n",
      " [139 242]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 70\n",
    "print(\"=\" * 50)\n",
    "print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "# Binarize target based on threshold\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# KNN model\n",
    "k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"KNN Model with k={k}\")\n",
    "print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc8677",
   "metadata": {},
   "source": [
    "### RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03f1a882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 70\n",
      "Model Accuracy: 62.31%\n",
      "Confusion Matrix:\n",
      " [[234 157]\n",
      " [134 247]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 70\n",
    "print(\"=\" * 50)\n",
    "print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "# Convert target variable: Popularity > threshold → 1, else 0\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Split data (80% train, 20% test) with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Feature scaling (optional for Random Forest, but kept for consistency)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train Random Forest model\n",
    "rfc = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    max_depth=20,\n",
    "    min_samples_split=5\n",
    ")\n",
    "rfc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rfc.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08d0e2",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59f35634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 70\n",
      "SVM Model Accuracy: 62.18%\n",
      "Confusion Matrix:\n",
      " [[198 193]\n",
      " [ 99 282]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 70\n",
    "print(\"=\" * 50)\n",
    "print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "# Convert popularity to binary target\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train SVM\n",
    "svm = SVC(kernel='rbf', C=1, probability=True, random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"SVM Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5597c4",
   "metadata": {},
   "source": [
    "### XGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c789f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Threshold: 70\n",
      "XGBoost Model Accuracy: 62.31%\n",
      "Confusion Matrix:\n",
      "[[151 240]\n",
      " [ 51 330]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 70\n",
    "print(\"=\" * 50)\n",
    "print(f\"Testing Threshold: {threshold}\")\n",
    "\n",
    "# Convert popularity to binary based on threshold\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=5\n",
    ")\n",
    "\n",
    "# Train model\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = xgb.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"XGBoost Model Accuracy: {accuracy:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda76454",
   "metadata": {},
   "source": [
    "### Stacking models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "307e02bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Accuracy: 63.34%\n",
      "Confusion Matrix:\n",
      "[[231 160]\n",
      " [123 258]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 70\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('svm', SVC(kernel='rbf', C=1, probability=True, random_state=42)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# Define meta-model (stacker)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create StackingClassifier\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Train stacked model\n",
    "stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = stacked_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Stacked Model Accuracy: {accuracy:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6864495a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Accuracy: 63.47%\n",
      "Confusion Matrix:\n",
      "[[228 163]\n",
      " [119 262]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 70\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('svm', SVC(kernel='rbf', C=1, probability=True, random_state=42)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "]\n",
    "\n",
    "# Define meta-model (stacker)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create StackingClassifier\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Train stacked model\n",
    "stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = stacked_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Stacked Model Accuracy: {accuracy:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a28de727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Accuracy: 87.17%\n",
      "Confusion Matrix:\n",
      "[[2595    9]\n",
      " [ 374    7]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 70\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# Define meta-model (stacker)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create StackingClassifier\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Train stacked model\n",
    "stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = stacked_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Stacked Model Accuracy: {accuracy:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2418dfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Accuracy (SVM as meta-model): 58.16%\n",
      "Confusion Matrix:\n",
      "[[207 184]\n",
      " [139 242]]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced.csv\")\n",
    "\n",
    "# Set threshold\n",
    "threshold = 70\n",
    "df['popularity'] = (df['popularity'] > threshold).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('logreg', LogisticRegression())\n",
    "]\n",
    "\n",
    "# Define meta-model (SVM)\n",
    "meta_model = SVC(kernel='rbf', C=1, probability=True, random_state=42)\n",
    "\n",
    "# Create StackingClassifier\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Train stacked model\n",
    "stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = stacked_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Stacked Model Accuracy (SVM as meta-model): {accuracy:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57587f75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
